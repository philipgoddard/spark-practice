# Some learnings of spark

I installed a local copy of 2.0.0 on my laptop in standalone mode. Not for powerhouse data crunching, but to learn.

I've also got cloudera's quickstart (not sure how up to date)- spark there is 1.x, but hive and all of that goodness is set up to practice there!


PySpark seems to default to python 2.7... not sure what the ramifications of using 3.x are. Need to investigate what python environment it is using... and where to install packages!

Can set to 3.x with

```
export PYSPARK_PYTHON=python3.5
```
